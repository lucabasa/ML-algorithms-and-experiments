__author__ = 'lucabasa'
__version__ = '1.0.0'
__status__ = 'development'

import source.hyperplots as hyp
from source.report import plot_predictions, make_results, store_results
from source.utility import cv_score, grid_search
import random
import pandas as pd


def skl_exp(model, data_name, features, kfolds, sample=False, store=False, coefs=True, store_name=None, parameters=None, model_name=None):
    '''
    This is a wrapper to perform an experiment on the data generated by sklearn
    model: pipeline of at least 2 steps
    data_name: path to the csv with the data
    kfolds: KFold instance to use
    sample: integer to select only a sample of the data
    store: boolean to store the result on a csv
    coefs: boolean, it true it plots the coefficients too
    store_name: path to file where the summary of the results is stored
    model_name: name of the model to be stored
    '''
    random.seed(666)
    df = pd.read_csv(data_name)
    if sample:
        df = df.sample(sample)
    
    coefs_name = data_name.split('.csv')[0] + '__coefficients.csv'
    target_name = data_name.split('/')[2].split('.csv')[0]

    target = df['target']
    
    df = pd.get_dummies(df, drop_first=True)

    df_train = df.drop('target', axis=1)

    oof, coefs_est = cv_score(df_train, target, kfolds, model, imp_coef=True)

    plot_predictions(df_train, target, oof, feature=None, hue=None, legend=False, savename=False)
    
    if coefs:
        hyp.plot_coefficients('tar_nonlin_3', coefs_est, coefs_real=coefs_name)
    
    if store:
        store_results(store_name, 
                      label=target, prediction=oof, model='LinearRegression', 
                      parameters={'Irrelavant'}, 
                      target_name=target_name, variables='All', instances=df_train.shape[0], verbose=True)
    else:
        res = make_results(label=target, prediction=oof, model='not_relevant', 
                           parameters={'Irrelavant'}, 
                           target_name=target_name, variables='All', instances=df_train.shape[0], verbose=True)


def lr_learning_curve(model, data_name, sample=None, scoring='neg_mean_absolute_error'):
    random.seed(666)
    df = pd.read_csv(data_name)
    if sample:
        df = df.sample(sample)
    
    title = data_name.split('/')[2].split('.csv')[0]

    target = df['target']

    df_train = df.drop('target', axis=1)

    hyp.plot_learning_curve(model, title, df_train, target, scoring=scoring)
        
        
def select_features(features, data, target_name, coef_names):
    random.seed(4561)
    if features == 'all':
        return data[[col for col in data.columns if 'tar_' not in col]]
    elif features == 'exact':
        return data[coef_names]
    elif features == 'exact-10':
        n_used = len(coef_names)
        to_use = random.sample(coef_names, int(n_used*0.9))
        return data[to_use]
    elif features == 'unobserved':
        n_used = len(coef_names)
        to_drop = random.sample(coef_names, int(n_used*0.1))
        return data[[col for col in data.columns if 'tar_' not in col]].drop(to_drop, axis=1)
    else:
        raise KeyError('Wrong feature selection provided. Use all, exact, exact-10, or unobserved')
        
        