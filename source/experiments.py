__author__ = 'lucabasa'
__version__ = '1.2.0'
__status__ = 'development'

import source.hyperplots as hyp
from source.report import plot_predictions, make_results, store_results
from source.utility import cv_score, grid_search
import random
import pandas as pd


def _import_generated_data(target_name):
    df = pd.read_csv('data/simulated/clean.csv')
    coefficients = pd.read_pickle('data/simulated/coefficients.pkl')
    coef_names = list(coefficients[target_name].feat.values)
    df['target'] = df[target_name]
    del df[target_name]
    coefs_file = None
    
    return df, coef_names, coefs_file


def _import_sklearn_data(data_name):
    df = pd.read_csv(data_name)
    coefs_file = data_name.split('.csv')[0] + '__coefficients.csv'
    
    true_coefficients = pd.read_csv(coefs_file)
    coef_names = list(true_coefficients.variable.unique())
    
    return df, coef_names, coefs_file


def make_exp(model, kfolds, data_name=None, target_name=None, features='all',
            sample=False, store=False, coefs=True, store_name=None, parameters=None, model_name=None):
    '''
    This is a wrapper to perform an experiment on the data generated by sklearn or by the generate_data module
    
    model: pipeline of at least 2 steps
    kfolds: KFold instance to use
    data_name: if used, indicates data generated via sklearn. If None, it will use the data generated by me
    target_name: Mandatory if data_name is None, it indicates which target variable we are considering
    features: string for feature selection
    sample: integer to select only a sample of the data
    store: boolean to store the result on a csv
    coefs: boolean, it true it plots the coefficients too
    store_name: path to file where the summary of the results is stored
    parameters: dictionary to be stored
    model_name: name of the model to be stored
    
    '''
    random.seed(666)
    if data_name is None:
        df, coef_names, coefs_file = _import_generated_data(target_name)
    else:
        df, coef_names, coefs_file = _import_sklearn_data(data_name)
        target_name = data_name.split('/')[2].split('.csv')[0]
    if sample:
        df = df.sample(sample)

    target = df['target']
    
    df = pd.get_dummies(df, drop_first=True)

    df_train = df.drop('target', axis=1)
    
    df_train = select_features(features, df_train, coef_names)

    oof, coefs_est = cv_score(df_train, target, kfolds, model, imp_coef=True)

    plot_predictions(df_train, target, oof, feature=None, hue=None, legend=False, savename=False)
    
    if coefs:
        hyp.plot_coefficients(target_name, coefs_est, coefs_real=coefs_file)
    
    if store:
        store_results(store_name, 
                      label=target, prediction=oof, model=model_name, 
                      parameters=parameters, 
                      target_name=target_name, variables=features, instances=df_train.shape[0], verbose=True)
    else:
        res = make_results(label=target, prediction=oof, model='not_relevant', 
                           parameters='not_relevant', 
                           target_name=target_name, variables=features, instances=df_train.shape[0], verbose=True)


def learning_curve(model, kfolds, data_name=None, target_name=None, 
                   features='all', sample=None, scoring='neg_mean_absolute_error'):
    '''
    Wrapper around hyp.plot_learning_curve to facilitate feature selection and instances selection
    
    model: anything with a fit and predict method (pipeline or not)
    data_name: if used, indicates data generated via sklearn. If None, it will use the data generated by me
    target_name: Mandatory if data_name is None, it indicates which target variable we are considering
    features: string for feature selection
    sample: if not None, selects a subsample of instances
    scoring: scoring function to evaluate the curves
    '''
    random.seed(666)
    if data_name is None:
        df, coef_names, coefs_file = _import_generated_data(target_name)
        title = target_name
    else:
        df, coef_names, coefs_file = _import_sklearn_data(data_name)
        title = data_name.split('/')[2].split('.csv')[0]
    if sample:
        df = df.sample(sample)

    target = df['target']
    df = pd.get_dummies(df, drop_first=True)

    df_train = df.drop('target', axis=1)
    
    df_train = select_features(features, df_train, coef_names)

    hyp.plot_learning_curve(model, title, df_train, target, scoring=scoring, cv=kfolds, n_jobs=-1)

        
def select_features(features, data, coef_names):
    random.seed(4561)
    if features == 'all':
        return data[[col for col in data.columns if 'tar_' not in col]]
    elif features == 'exact':
        return data[coef_names]
    elif features == 'exact-10':
        n_used = len(coef_names)
        to_use = random.sample(coef_names, int(n_used*0.9))
        return data[to_use]
    elif features == 'unobserved':
        n_used = len(coef_names)
        to_drop = random.sample(coef_names, int(n_used*0.1))
        return data[[col for col in data.columns if 'tar_' not in col]].drop(to_drop, axis=1)
    else:
        raise KeyError('Wrong feature selection provided. Use all, exact, exact-10, or unobserved')
        
        